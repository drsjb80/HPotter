#HTTP Commands Anomaly Detection
A machine learning algorithm that detects anomalous HTTP requests. 
 

[![Build Status](https://travis-ci.org/drsjb80/HPotter.svg?branch=master)](https://travis-ci.org/drsjb80/HPotter) 
##Training and Predictions
To ensure the necessary packages are installed, do:

    pip3 install -r requirements.txt 
 
To train the machine learning algorithm itself, do:

    python3 -m hpotter.machine_learning.http_commands.learn

To make predictions using a saved model checkpoint after training, do:

    python3 -m hpotter.machine_learning.http_commands.predict
 
Once the machine learning algorithm is trained and predictions are made, there will be a file named 
`anomaly_report.html` in the `hpotter/machine_learning/http_commands` directory that contains
the HTTP requests that were detected as anomalies. This HTML file holds each malicious HTTP request
and the associated characters that contributed to the anomalous prediction highlighted in red. 
  
Below samples an output from `anomaly_report.html`:
  
    ADD IMAGE HERE!
  
##Additional Details
###Training Datasets
The model is set to train over 60 epochs or until a minimum average training loss of 0.20 or lower is 
achieved. It is trained on 30,000 benign samples from the `hpotter/machine_learning/http_commands/data/benign_requests.txt`
file and 15,402 anomalous samples from the `anomalous_requests.txt` file in the same directory.
  
###Saved Model Checkpoints
Training the model takes time, and as such it is important to have checkpoints in the model's training
process if adjustments need to be made. These checkpoints are stored in the `hpotter/machine_learning/http_commands/checkpoints`
directory are used to make predictions on future HTTP requests.

###Model Definition
The model used is a sequence-to-sequence Long-Short-Term-Memory (LSTM) Recurrent Neural Network (RNN).
The premise of a sequence-to-sequence LSTM is to map a given input sequence (text in the form of an HTTP request)
to an encoded vector, and the algorithm will try to re-create the input it has seen as its output. This is depicted
below:

![Screen Shot 2019-09-16 at 9 13 15 PM](https://user-images.githubusercontent.com/32188816/65008534-f100da80-d8c6-11e9-87e3-c071a73ca26f.png)

The idea is that if the model is given an anomalous sample, it will generate an excessive amount of errors
because of never having seen such a sample before. After training the model, below shows the complete model
architecture generated by TensorBoard. 

![Screen Shot 2019-09-16 at 9 25 53 PM](https://user-images.githubusercontent.com/32188816/65009073-ad0ed500-d8c8-11e9-88f9-0c1159f19bd6.png)
